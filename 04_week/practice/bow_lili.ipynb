{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting the occurence of words in language\n",
    "\n",
    "#### Pros\n",
    "* Works for any text\n",
    "* Easy and fast to do\n",
    "* Does not require a language model (just the corpus)\n",
    "\n",
    "#### Cons\n",
    "* Does not apply language knowledge (stopwords EN only)\n",
    "* Order of words is ignored\n",
    "* Uniqueness of words is not accentuated ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = [\"Ben Howard\", \"The Doors\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [artists[0]]*3 + [artists[1]]*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corups is a collection of the documents.\n",
    "corpus = [\"\"\"Living without her\n",
    "Living at all\n",
    "Seems to slow me down\n",
    "Living forever\n",
    "Hell, I don't know\n",
    "Do I care, do I care\n",
    "The thunder's rumbled sound\"\"\",\n",
    "          \"\"\"Wrapped up in dissonance\n",
    "I'm sorry that I just walked away\n",
    "Lost in the insignificance of mine\n",
    "I had no words to say\"\"\",\n",
    "          \"\"\"Hold it in, the river in your mouth is pouring out\n",
    "Water takes the shape of all that it surrounds\n",
    "Yeah I know, I've been trying so hard\n",
    "To keep in time with all of the hours in your day\"\"\",\n",
    "          \"\"\"People are strange when you're a stranger\n",
    "Faces look ugly when you're alone\n",
    "Women seem wicked when you're unwanted\n",
    "Streets are uneven when you're down\"\"\",\n",
    "          \"\"\"You know that it would be untrue\n",
    "You know that I would be a liar\n",
    "If I was to say to you\n",
    "Girl, we couldn't get much higher\n",
    "\"\"\", \n",
    "          \"\"\"This is the end\n",
    "Beautiful friend\n",
    "This is the end\n",
    "My only friend, the end\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_corpus = cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6x95 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 113 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sparse Matrix\n",
    "Most of our matrix consists of zeroes. A Sparse Matrix only stores the non-zero values to save memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 2, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "         0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 3, 0, 0, 1, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "         0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "         0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       "        [2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 1, 0, 0, 0, 1, 1, 0, 4, 0, 1, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 0, 2, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "         0, 0, 1, 1, 1, 3, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "         0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 2],\n",
       "        [0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 1, 0, 4, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         4, 1, 0, 0, 1, 0, 0, 0, 0, 4, 0],\n",
       "        [0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "         0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 0, 0,\n",
       "         0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "         0, 0, 0, 0, 0, 0, 2, 0, 0, 3, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 2, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_corpus.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>alone</th>\n",
       "      <th>are</th>\n",
       "      <th>at</th>\n",
       "      <th>away</th>\n",
       "      <th>be</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>been</th>\n",
       "      <th>care</th>\n",
       "      <th>couldn</th>\n",
       "      <th>...</th>\n",
       "      <th>wicked</th>\n",
       "      <th>with</th>\n",
       "      <th>without</th>\n",
       "      <th>women</th>\n",
       "      <th>words</th>\n",
       "      <th>would</th>\n",
       "      <th>wrapped</th>\n",
       "      <th>yeah</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ben Howard</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ben Howard</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ben Howard</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Doors</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Doors</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Doors</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            all  alone  are  at  away  be  beautiful  been  care  couldn  ...  \\\n",
       "Ben Howard    1      0    0   1     0   0          0     0     2       0  ...   \n",
       "Ben Howard    0      0    0   0     1   0          0     0     0       0  ...   \n",
       "Ben Howard    2      0    0   0     0   0          0     1     0       0  ...   \n",
       "The Doors     0      1    2   0     0   0          0     0     0       0  ...   \n",
       "The Doors     0      0    0   0     0   2          0     0     0       1  ...   \n",
       "The Doors     0      0    0   0     0   0          1     0     0       0  ...   \n",
       "\n",
       "            wicked  with  without  women  words  would  wrapped  yeah  you  \\\n",
       "Ben Howard       0     0        1      0      0      0        0     0    0   \n",
       "Ben Howard       0     0        0      0      1      0        1     0    0   \n",
       "Ben Howard       0     1        0      0      0      0        0     1    0   \n",
       "The Doors        1     0        0      1      0      0        0     0    4   \n",
       "The Doors        0     0        0      0      0      2        0     0    3   \n",
       "The Doors        0     0        0      0      0      0        0     0    0   \n",
       "\n",
       "            your  \n",
       "Ben Howard     0  \n",
       "Ben Howard     0  \n",
       "Ben Howard     2  \n",
       "The Doors      0  \n",
       "The Doors      0  \n",
       "The Doors      0  \n",
       "\n",
       "[6 rows x 95 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(vectorized_corpus.todense(),index=labels,columns=cv.get_feature_names())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Tf-Idf Transformer:\n",
    "\n",
    "#### (Counting plus scaling - both by document and by word)\n",
    "\n",
    "* TF - Term Frequency (same as Count Vectorizer)\n",
    "* IDF - Inverse Document Frequency\n",
    "\n",
    "$TFIDF = TF(w,d) * IDF(w)$\n",
    "\n",
    "$IDF(w) = log(\\frac{1+ no.documents}{1 + no.documents containing word w})+1$\n",
    "\n",
    "##### The steps for calculating TFIDF are:\n",
    "* For each vector:\n",
    "    * Calculate the term frequency for each term in the vector\n",
    "    * Calculate the inverse doc frequency for each term in the vector\n",
    "    * Multiply the two for each term in the vector\n",
    "* Then normalise each vector by the Euclidean norm (numpy.linalg.norm)\n",
    "    * $norm = \\frac{v}{||v||^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid=tfid.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfid = pd.DataFrame(tfid.todense(), index = labels, columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>alone</th>\n",
       "      <th>are</th>\n",
       "      <th>at</th>\n",
       "      <th>away</th>\n",
       "      <th>be</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>been</th>\n",
       "      <th>care</th>\n",
       "      <th>couldn</th>\n",
       "      <th>...</th>\n",
       "      <th>wicked</th>\n",
       "      <th>with</th>\n",
       "      <th>without</th>\n",
       "      <th>women</th>\n",
       "      <th>words</th>\n",
       "      <th>would</th>\n",
       "      <th>wrapped</th>\n",
       "      <th>yeah</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ben Howard</th>\n",
       "      <td>0.146040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.178095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.35619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.178095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ben Howard</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.234289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.234289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.234289</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ben Howard</th>\n",
       "      <td>0.236771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14437</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.14437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.14437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.28874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Doors</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128638</td>\n",
       "      <td>0.257276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128638</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.421940</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Doors</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.361321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.180661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.361321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.444433</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 all     alone       are        at      away        be  \\\n",
       "Ben Howard  0.146040  0.000000  0.000000  0.178095  0.000000  0.000000   \n",
       "Ben Howard  0.000000  0.000000  0.000000  0.000000  0.234289  0.000000   \n",
       "Ben Howard  0.236771  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "The Doors   0.000000  0.128638  0.257276  0.000000  0.000000  0.000000   \n",
       "The Doors   0.000000  0.000000  0.000000  0.000000  0.000000  0.361321   \n",
       "\n",
       "            beautiful     been     care    couldn  ...    wicked     with  \\\n",
       "Ben Howard        0.0  0.00000  0.35619  0.000000  ...  0.000000  0.00000   \n",
       "Ben Howard        0.0  0.00000  0.00000  0.000000  ...  0.000000  0.00000   \n",
       "Ben Howard        0.0  0.14437  0.00000  0.000000  ...  0.000000  0.14437   \n",
       "The Doors         0.0  0.00000  0.00000  0.000000  ...  0.128638  0.00000   \n",
       "The Doors         0.0  0.00000  0.00000  0.180661  ...  0.000000  0.00000   \n",
       "\n",
       "             without     women     words     would   wrapped     yeah  \\\n",
       "Ben Howard  0.178095  0.000000  0.000000  0.000000  0.000000  0.00000   \n",
       "Ben Howard  0.000000  0.000000  0.234289  0.000000  0.234289  0.00000   \n",
       "Ben Howard  0.000000  0.000000  0.000000  0.000000  0.000000  0.14437   \n",
       "The Doors   0.000000  0.128638  0.000000  0.000000  0.000000  0.00000   \n",
       "The Doors   0.000000  0.000000  0.000000  0.361321  0.000000  0.00000   \n",
       "\n",
       "                 you     your  \n",
       "Ben Howard  0.000000  0.00000  \n",
       "Ben Howard  0.000000  0.00000  \n",
       "Ben Howard  0.000000  0.28874  \n",
       "The Doors   0.421940  0.00000  \n",
       "The Doors   0.444433  0.00000  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_vec = TfidfVectorizer()\n",
    "tfid_vec_trans = tfid_vec.fit(corpus)\n",
    "tfidtrans_corpus=tfid_vec_trans.transform(corpus)\n",
    "#tfidtrans = TfidfTransformer()\n",
    "#tfidtrans.fit(tfid_vec_corpus)\n",
    "#tfidtrans_corpus = tfidtrans.transform(tfid_vec_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building TF-IDF from the ground up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38842822434289515"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "n_docs = 4\n",
    "doc_freq = 4\n",
    "tf = 1.0\n",
    "idf = math.log((n_docs) / (1+doc_freq)) + 1\n",
    "\n",
    "(tf * idf) / math.sqrt(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 95)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidtrans_corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression()\n",
    "m.fit(tfidtrans_corpus, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction for a new song "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['The Doors'], dtype='<U10')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(tfid_vec_trans.transform(['this is a song']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "domestic-atmosphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dropout, Dense, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-conservation",
   "metadata": {},
   "source": [
    "# Task 2: Deep Learning (Estimated time: 15 min)\n",
    "- The provided code includes errors.\n",
    "- Please identify the errors and describe then in 1-2\n",
    "sentences. Result to hand in: a txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-letter",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This is a CNN network, the aim is at handeling 16 pictures, with 3 classes. However befor loading img, we need to do 2 steps:\n",
    "1. turn img into fload data type, using image.img_to_array(img) \n",
    "2. ture size into shpe (1, 224, 224, 3) using np.expand_dims(x, axis=0)# sizeä¸º(1, 224, 224, 3)\n",
    "3. the last layer using /activation='sigmoid'/ is not correct if it is a 3 classes classfier. However softmax would pass better. \n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "id": "isolated-essay",
   "metadata": {},
   "source": [
    "IMG_SHAPE = (224, 224, 3) \n",
    "IMG_SIZE = (IMG_SHAPE[0], IMG_SHAPE[1]) \n",
    "batch_size = 16\n",
    "num_classes = 3\n",
    "\n",
    "def get_paths():\n",
    "    # Let's assume that this function returns a list of tuples of (path_to_img, class_label) sorted by class_label\n",
    "    pass\n",
    "\n",
    "\n",
    "def load_data(path, image_size, augment, batch_size):\n",
    "    # Assume that this function returns a tf dataset object.\n",
    "    # Images are resized to image_size, normalized between 0 and 1 and bundled to batches of batch_size.\n",
    "    # If augment = True, data augmentation is applied.\n",
    "    pass\n",
    "\n",
    "\n",
    "paths = get_paths()\n",
    "val_split = 0.2\n",
    "num_samples = len(paths)\n",
    "val_path = paths[:val_split * num_samples]\n",
    "train_path = paths[:(1 - val_split) * num_samples]\n",
    "\n",
    "train_loader = load_data(train_path, image_size=IMG_SIZE, augment=True, batch_size=batch_size)\n",
    "val_loader = load_data(val_path, image_size=IMG_SIZE, augment=True, batch_size=batch_size)\n",
    "\n",
    "# Do transfer learning from VGG\n",
    "model_vgg16 = tf.keras.applications.vgg16.VGG16(\n",
    "    include_top=False, weights='imagenet', input_shape=IMG_SIZE)\n",
    "x = Flatten()(model_vgg16.output)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='sigmoid')(x)\n",
    "model = Model(inputs=model_vgg16.input, outputs=predictions)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "history = model.fit(train_loader,\n",
    "                    steps_per_epoch=len(train_path) * batch_size,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=50,\n",
    "                    validation_data=val_loader,\n",
    "                    validation_steps=len(val_path) * batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
